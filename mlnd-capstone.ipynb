{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Nanodegree - Capstone Project\n",
    "\n",
    "## Distracted Driver Detection\n",
    "\n",
    "## Project: Write a program to detect distracted drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing import image                  \n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt   \n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_files       \n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, log_loss\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driving_class_to_description = {\n",
    "    \"c0\": \"safe driving\",\n",
    "    \"c1\": \"texting - right\",\n",
    "    \"c2\": \"talking on the phone - right\",\n",
    "    \"c3\": \"texting - left\",\n",
    "    \"c4\": \"talking on the phone - left\",\n",
    "    \"c5\": \"operating the radio\",\n",
    "    \"c6\": \"drinking\",\n",
    "    \"c7\": \"reaching behind\",\n",
    "    \"c8\": \"hair and makeup\",\n",
    "    \"c9\": \"talking to passenger\",\n",
    "    0: \"safe driving\",\n",
    "    1: \"texting - right\",\n",
    "    2: \"talking on the phone - right\",\n",
    "    3: \"texting - left\",\n",
    "    4: \"talking on the phone - left\",\n",
    "    5: \"operating the radio\",\n",
    "    6: \"drinking\",\n",
    "    7: \"reaching behind\",\n",
    "    8: \"hair and makeup\",\n",
    "    9: \"talking to passenger\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    driver_files = np.array(data['filenames'])\n",
    "    driver_targets = np_utils.to_categorical(np.array(data['target']), 10)\n",
    "    # split into test/train here?\n",
    "    return driver_files, driver_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "all_files, all_targets = load_dataset('StateFarm/imgs/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_df = pd.read_csv('StateFarm/driver_imgs_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = file_df.subject.unique()\n",
    "print('There are %d subjects with data'% len(subjects))\n",
    "\n",
    "train_subjects = subjects[:-4]\n",
    "validate_subjects = subjects[-4:-3]\n",
    "test_subjects = subjects[-3:]\n",
    "print('Training subjects:')\n",
    "print(train_subjects)\n",
    "print('Validate subjects:')\n",
    "print(validate_subjects)\n",
    "print('Test subjects:')\n",
    "print(test_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = file_df.loc[file_df['subject'].isin(test_subjects)]\n",
    "validate_rows = file_df.loc[file_df['subject'].isin(validate_subjects)]\n",
    "train_rows = file_df.loc[file_df['subject'].isin(train_subjects)]\n",
    "\n",
    "train_files = train_rows.apply(lambda x: \"{}/{}\".format(x[1],x[2]), axis=1)\n",
    "validate_files = validate_rows.apply(lambda x: \"{}/{}\".format(x[1],x[2]), axis=1)\n",
    "test_files = test_rows.apply(lambda x: \"{}/{}\".format(x[1],x[2]), axis=1)\n",
    "\n",
    "print(\"train_files count: {}\".format(len(train_files)))\n",
    "print(\"validate_files count: {}\".format(len(validate_files)))\n",
    "print(\"test_files count: {}\".format(len(test_files)))\n",
    "\n",
    "train_classes = train_files.apply(lambda x: x.split('/')[0].split('c')[1])\n",
    "train_classes_categories = np_utils.to_categorical(train_classes)\n",
    "validate_classes = validate_files.apply(lambda x: x.split('/')[0].split('c')[1])\n",
    "validate_classes_categories = np_utils.to_categorical(validate_classes)\n",
    "test_classes = test_files.apply(lambda x: x.split('/')[0].split('c')[1])\n",
    "test_classes_categories = np_utils.to_categorical(test_classes)\n",
    "\n",
    "assert len(train_classes) == len(train_files)\n",
    "assert len(train_classes) == len(train_classes_categories)\n",
    "\n",
    "assert len(validate_classes) == len(validate_files)\n",
    "assert len(validate_classes) == len(validate_classes_categories)\n",
    "\n",
    "assert len(test_classes) == len(test_files)\n",
    "assert len(test_classes) == len(test_classes_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(\"{}/{}\".format('StateFarm/imgs/train', img_path), target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "validate_tensors = paths_to_tensor(validate_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255\n",
    "\n",
    "train_classes_categories = train_classes_categories\n",
    "validate_classes_categories = validate_classes_categories\n",
    "test_classes_categories = test_classes_categories\n",
    "\n",
    "assert len(train_files) == len(train_tensors)\n",
    "assert len(validate_files) == len(validate_tensors)\n",
    "assert len(test_files) == len(test_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.argmax(train_classes_categories, axis=1))\n",
    "plt.title('Training Class Distribution')\n",
    "plt.xlabel('Image Count')\n",
    "plt.ylabel('Driving Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_class_sample(tcc, tensors):\n",
    "    fig = plt.figure(figsize=(50, 50))  # width, height in inches\n",
    "    dim = 4\n",
    "    for target_class in range(10):\n",
    "        c = np.argmax(tcc, axis=1)\n",
    "        idx = np.where(c == target_class)[0][0]\n",
    "        tensor = tensors[idx]\n",
    "        sub = fig.add_subplot(dim, dim, target_class + 1)\n",
    "        sub.imshow(tensor, interpolation='nearest')\n",
    "        text_params = {'fontweight': 'bold'}\n",
    "\n",
    "        sub.text(0,\n",
    "                 10,\n",
    "                 \"actual: {}\".format(driving_class_to_description[target_class]),\n",
    "                 color='g',\n",
    "                 size=20,\n",
    "                 bbox=dict(boxstyle=\"square\", ec=(1., 0.5, 0.5), fc=(1., 0.8, 0.8), ),\n",
    "                 **text_params)\n",
    "    plt.savefig('analysis/sample.png', format='png')\n",
    "        \n",
    "show_class_sample(train_classes_categories, train_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8\n",
    "# https://www.safaribooksonline.com/library/view/python-deep-learning/9781787125193/a0b05e70-9f53-404c-a975-09ac766389a1.xhtml\n",
    "# https://alexisbcook.github.io/2017/using-transfer-learning-to-classify-images-with-keras/\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "nb_train_samples = len(train_tensors)\n",
    "nb_validation_samples = len(validate_tensors) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_params_fast():\n",
    "    return 75, 1\n",
    "\n",
    "def train_params_full():\n",
    "    return 20, 20\n",
    "\n",
    "def optimizer_1(model):\n",
    "    lr=0.0001\n",
    "    momentum=0.9\n",
    "    opt=\"SGD\"\n",
    "    model.compile(loss = \"categorical_crossentropy\",\n",
    "                  optimizer = optimizers.SGD(lr=lr, momentum=momentum),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return \"opt={},lr={},momentum={}\".format(opt,lr, momentum)\n",
    "\n",
    "def optimizer_2(model):\n",
    "    lr=0.0001\n",
    "    momentum=\"default\"\n",
    "    opt=\"Adam\"\n",
    "    model.compile(loss = \"categorical_crossentropy\",\n",
    "                  optimizer = optimizers.Adam(lr=lr),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return \"opt={},lr={},momentum={}\".format(opt,lr, momentum)\n",
    "\n",
    "def model_v1():\n",
    "    pretrain_model = applications.ResNet50(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "    train_layers = 0\n",
    "    for layer in pretrain_model.layers[:-train_layers]:\n",
    "        layer.trainable = False\n",
    "    x = pretrain_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "    # creating the final model \n",
    "    model = Model(input = pretrain_model.input, output = predictions)\n",
    "    return model, \"resnet50-flat-drop0.5\"\n",
    "\n",
    "def model_v2():\n",
    "    pretrain_model = applications.ResNet50(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "    train_layers = 0\n",
    "    for layer in pretrain_model.layers[:-train_layers]:\n",
    "        layer.trainable = False\n",
    "    x = pretrain_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    predictions = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "    # creating the final model \n",
    "    model = Model(input = pretrain_model.input, output = predictions)\n",
    "    return model, \"resnet50-flat-d1024-drop0.5-dense1024\"\n",
    "\n",
    "def model_v3():\n",
    "    pretrain_model = applications.ResNet50(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "    train_layers = 0\n",
    "    for layer in pretrain_model.layers[:-train_layers]:\n",
    "        layer.trainable = False\n",
    "    x = pretrain_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "    # creating the final model \n",
    "    model = Model(input = pretrain_model.input, output = predictions)\n",
    "    return model, \"resnet50-model-v3\"\n",
    "\n",
    "def model_v4():\n",
    "    pretrain_model = applications.ResNet50(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "    train_layers = 0\n",
    "    for layer in pretrain_model.layers[:-train_layers]:\n",
    "        layer.trainable = False\n",
    "    x = pretrain_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "    # creating the final model \n",
    "    model = Model(input = pretrain_model.input, output = predictions)\n",
    "    return model, \"resnet50-model-v4\"\n",
    "\n",
    "def model_v5():\n",
    "    pretrain_model = applications.ResNet50(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "    train_layers = 0\n",
    "    for layer in pretrain_model.layers[:-train_layers]:\n",
    "        layer.trainable = False\n",
    "    x = pretrain_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "    # creating the final model \n",
    "    model = Model(input = pretrain_model.input, output = predictions)\n",
    "    return model, \"resnet50-model-v5\"\n",
    "\n",
    "batch_size, epochs = train_params_full()\n",
    "model_final, model_name = model_v5()\n",
    "model_optimizer_text = optimizer_1(model_final)\n",
    "\n",
    "model_desc = \"batch_size={},epochs={},{},{}\".format(batch_size, epochs, model_name, model_optimizer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_desc)\n",
    "# model_final.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train():\n",
    "    checkpoint = ModelCheckpoint(\"weights/{}.h5\".format(model_desc), \n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True, \n",
    "                                 save_weights_only=False, \n",
    "                                 mode='auto', \n",
    "                                 period=1)\n",
    "    early = EarlyStopping(monitor='val_loss', \n",
    "                          min_delta=0, \n",
    "                          patience=10, \n",
    "                          verbose=1, \n",
    "                          mode='auto')\n",
    "\n",
    "    history = model_final.fit(x=train_tensors,\n",
    "                              y=train_classes_categories,\n",
    "                              batch_size=batch_size,\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              validation_data=(validate_tensors, validate_classes_categories),\n",
    "                              callbacks = [checkpoint, early]\n",
    "                              )\n",
    "    return history\n",
    "history = None\n",
    "# Comment this out if prior weights have been computed for this model\n",
    "# Useful to modify analysis code without rerunning training\n",
    "\n",
    "history = do_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_accuracy_fig(hist, desc):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.plot(np.arange(len(hist.history['acc'])), hist.history['acc'], label='training')\n",
    "    plt.plot(np.arange(len(hist.history['val_acc'])), hist.history['val_acc'], label='validation')\n",
    "    plt.title('Accuracy\\n {}'.format(desc))\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('accuracy ')\n",
    "    plt.legend(loc=0)\n",
    "    plt.savefig('analysis/acc{}.png'.format(desc), format='png')\n",
    "    plt.show()\n",
    "if history is not None:\n",
    "    generate_accuracy_fig(history, model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_loss_fig(hist, desc):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.plot(np.arange(len(hist.history['loss'])), hist.history['loss'], label='loss')\n",
    "    plt.plot(np.arange(len(hist.history['val_loss'])), hist.history['val_loss'], label='val_loss')\n",
    "    plt.title('Loss\\n {}'.format(desc))\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss ')\n",
    "    plt.legend(loc=0)\n",
    "    plt.savefig('analysis/loss{}.png'.format(desc), format='png')\n",
    "    plt.show()\n",
    "if history is not None:\n",
    "    generate_loss_fig(history, model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.load_weights(\"weights/{}.h5\".format(model_desc))\n",
    "test_predictions = model_final.predict(x=test_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_metrics(pred, actual):\n",
    "    actual_classes = np.argmax(actual, axis=1)\n",
    "    predicted_classes = np.argmax(pred, axis=1)\n",
    "\n",
    "    test_accuracy = 100*np.sum(actual_classes==predicted_classes)/len(actual)\n",
    "    loss = log_loss(y_pred=pred, y_true=actual)\n",
    "\n",
    "    return \"Test accuracy: %.4f%%\\nLog loss: %f\" % (test_accuracy, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results = prediction_metrics(test_predictions, test_classes_categories)\n",
    "with open(\"analysis/test-results{}.txt\".format(model_desc), \"w\") as text_file:\n",
    "    text_file.write(test_results)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_attentive = [1.0] + [0] * 9\n",
    "benchmark_all_pred_attentive = [pred_attentive] * len(test_classes_categories)\n",
    "\n",
    "print(prediction_metrics(benchmark_all_pred_attentive, test_classes_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(test_predictions, axis=1)\n",
    "actual_classes = np.argmax(test_classes_categories, axis=1)\n",
    "\n",
    "def generate_mispredict_fig():\n",
    "    fig = plt.figure(figsize=(50, 50))  # width, height in inches\n",
    "    j = 0\n",
    "    dim = 4\n",
    "    for i in shuffle(range(len(test_tensors))):\n",
    "        tensor = test_tensors[i]\n",
    "        if predicted_classes[i] != actual_classes[i]:\n",
    "            sub = fig.add_subplot(dim, dim, j + 1)\n",
    "            sub.imshow(tensor, interpolation='nearest')\n",
    "            text_params = {'fontweight': 'bold'}\n",
    "            sub.text(0,\n",
    "                     10,\n",
    "                     \"pred: {}\".format(driving_class_to_description[predicted_classes[i]]),\n",
    "                     color='r',\n",
    "                     size=20,\n",
    "                     bbox=dict(boxstyle=\"square\", ec=(1., 0.5, 0.5), fc=(1., 0.8, 0.8), ),\n",
    "                     **text_params)\n",
    "            sub.text(0, \n",
    "                     25, \n",
    "                     \"actual: {}\".format(driving_class_to_description[actual_classes[i]]), \n",
    "                     color='g',\n",
    "                     size=20,\n",
    "                     bbox=dict(boxstyle=\"square\", ec=(1., 0.5, 0.5), fc=(1., 0.8, 0.8), ),\n",
    "                     **text_params)\n",
    "\n",
    "            j = j + 1\n",
    "            if j == dim * dim:\n",
    "                break\n",
    "    plt.savefig('analysis/mispredicts.png', format='png')\n",
    "generate_mispredict_fig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_confusion_fig():   \n",
    "    confusion = confusion_matrix(actual_classes, predicted_classes)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    hm = sns.heatmap(confusion, annot=True, fmt=\"d\")\n",
    "    hm.set_ylabel('True label')\n",
    "    hm.set_xlabel('Predicted label')\n",
    "    hm.set_title('Confusion Matrix\\n{}'.format(model_desc))\n",
    "    plt.savefig('analysis/confusion{}.png'.format(model_desc), format='png')\n",
    "generate_confusion_fig()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
